# Proyecto: Detecci√≥n automatizada de asentamientos humanos a partir de im√°genes satelitales

Este proyecto desarrolla un modelo de **clasificaci√≥n binaria** para detectar la **presencia o ausencia de asentamientos humanos** en im√°genes satelitales Landsat mediante **machine learning**. Dicho proyecto forma parte de la asignatura Machine Learning dirigida por el Dr. Hugo Carlos Mart√≠nez, del Posgrado Integrado en Ciencias de Informaci√≥n Geoespacial de [CentroGeo](https://www.centrogeo.org.mx/).

---

## Objetivo
El objetivo es construir un modelo robusto y escalable que pueda identificar asentamientos humanos a partir de im√°genes satelitales, considerando tanto escenarios balanceados como desbalanceados.

---

## Dataset
El conjunto de datos fue obtenido de datos del **INEGI** en un reto de ciencia de datos:  
üìÇ [Google Drive Dataset](https://drive.google.com/drive/folders/1UgnUSvjYG3G9-1ZIqNnZuKAalWcfMGTe?usp=drive_link)

- **Training set**: 1.1 millones de muestras  
- Cada muestra es un parche de **16x16 p√≠xeles** con **6 bandas espectrales**:
  - Azul (Blue)  
  - Verde (Green)  
  - Rojo (Red)  
  - Infrarrojo cercano (NIR)  
  - Infrarrojo de onda corta 1 (SWIR1)  
  - Infrarrojo de onda corta 2 (SWIR2)  

El dataset incluye **ruido e incertidumbre**, propios de la teledetecci√≥n y el etiquetado manual.

---

## Soluci√≥n Inicial (Balanced)
Pasos principales:
1. Exploraci√≥n y an√°lisis de la distribuci√≥n de clases.  
2. Aplicaci√≥n de undersampling como estrategia de balanceo.  
3. Extracci√≥n de **features estad√≠sticos/espectrales**. Para cada muestra,
se calcularon caracter√≠sticas tanto en el dominio espacial
como en el dominio de la frecuencia. En el dominio de
la frecuencia se utiliz√≥ la Transformada R√°pida de Fourier (FFT). 
4. Entrenamiento con modelos tradicionales (**Random Forest y Logistic Regression**).  
5. Evaluaci√≥n con m√©tricas:
   - **Accuracy**  
   - **F1 Score**  
   - **Recall**  

---

## Soluci√≥n Avanzada (Imbalanced)
En esta etapa se entrena con el **dataset original desbalanceado**. Se implementaron t√©cnicas para mitigar el sesgo:
- Pesos balanceados en los modelos (`class_weight="balanced"`)  
- Ajuste de umbrales de decisi√≥n  
- Calibraci√≥n de probabilidades  
- Uso de m√©tricas adicionales: **AUC-ROC, F1 minor√≠a**  

Incluye un **an√°lisis comparativo** entre el enfoque balanceado y el desbalanceado, destacando trade-offs entre recall y precisi√≥n.  

---

## Resultados
### Desempe√±o de la Regresi√≥n Log√≠stica antes y despu√©s de la normalizaci√≥n

| Condici√≥n              | Accuracy | F1 Score | Recall |
|------------------------|----------|----------|--------|
| Antes de normalizar    | 0.5696   | 0.56     | 0.57   |
| Despu√©s de normalizar  | 0.77     | 0.77     | 0.77   |

### Comparaci√≥n de desempe√±o entre modelos en el conjunto de validaci√≥n

| Modelo         | F1     | Exactitud | Recall  |
|----------------|--------|-----------|---------|
| Random Forest  | 0.8054 | 0.8057    | 0.8038  |
| Reg. Log√≠stica | 0.77   | 0.77      | 0.77    |

---

### Importancia de variables en el modelo **Random Forest**
1. Mediana: **0.2521**  
2. FFT mean: **0.1196**  
3. Curtosis: **0.1193**  
4. Dispersi√≥n: **0.1108**  

---

### Matriz de confusi√≥n del modelo **Random Forest**

|            | Pred 0 | Pred 1 |
|------------|--------|--------|
| **Real 0** | 14,722 |  5,278 |
| **Real 1** |  4,867 | 15,133 |

### An√°lisis del desempe√±o de la Regresi√≥n Log√≠stica con y sin normalizaci√≥n

El reporte de clasificaci√≥n **sin normalizaci√≥n** evidenci√≥ un **sesgo hacia la clase positiva (asentamiento)**, logrando un **recall de 0.70 en la clase 1** pero sacrificando precisi√≥n y desempe√±o general, con un **accuracy global de 0.57**.  
Esto indica que, sin normalizaci√≥n, el modelo favorece la detecci√≥n de positivos pero genera **muchos falsos positivos**, afectando la confiabilidad de las predicciones.

En contraste, al aplicar **normalizaci√≥n**, el modelo alcanz√≥ un desempe√±o equilibrado con m√©tricas cercanas a **0.77 en ambas clases** (accuracy, F1 Score y recall), mostrando un comportamiento mucho m√°s **robusto y consistente**.  
La normalizaci√≥n permiti√≥ que todas las variables contribuyeran de manera proporcional al aprendizaje, evitando que caracter√≠sticas con magnitudes mayores dominaran el entrenamiento.

Estos resultados confirman la importancia de la **normalizaci√≥n en modelos lineales como la Regresi√≥n Log√≠stica**, ya que facilita un aprendizaje m√°s estable y mejora la capacidad predictiva del clasificador.

---


##  Requisitos
- Python 3.9+  
- Librer√≠as:
  - `numpy`, `pandas`, `scikit-learn`, `scipy`
  - `matplotlib`, `seaborn`
  - `h5py`
  - `jupyter`  


## Autores

- Katia M. Villarnobo G.
- Jaziel Carballo-Tadeo

## Referencias

- INEGI (Dataset del concurso de ciencia de datos)
- Solo Electr√≥nicos, C√≥mo crear un dataset en el formato H5, 9 diciembre 2021. [En l√≠nea]. [Accedido: 9 agosto 2025].
- Documentaci√≥n de Scikit-learn
- L. Breiman, Random forests, \textit{Machine Learning}, vol. 45, no. 1, pp. 5‚Äì32, 2001.
- A Wavelet Tour of Signal Processing, Academic Press, 2008.
- D. W. Hosmer, S. Lemeshow, and R. X. Sturdivant, Applied Logistic Regression, 3rd ed., Wiley, 2013.

